---
title: Vulkan复习(优化、绘制矩形)
date: 2025-10-23 12:00:00 +0800
categories: [Vulkan]
tags: []     # TAG names should always be lowercase
math: true
---

# 帧并行

* log测试imageCount为3，因此说明swapchain为三缓冲
* 每帧流程：acquire（请求图像）->record（录制命令）->submit（执行命令和渲染）->present（交换链交换，并被显示器读取）
* 注意：
  * 对于三缓冲，一个front被显示器读取，无法acquire，两个back，被使用时无法acquire，空闲的可以被acquire，当无法acquire时会阻塞CPU指令，由于CPU启动GPU执行，因此也会阻塞GPU执行
  * Semaphores的等待是GPU的等待，也就是CPU的vkQueuePresentKHR指令会执行，只是GPU接收指令后会等待Semaphores发出信号后才会真正执行
  * 三缓冲才会实现并行，因为双缓冲时，一个front被显示器读取，无法acquire，一个back，正被使用时无法acquire，因此没有额外可acquire的图像
  * 三缓冲只需要2个CommandBuffer，一个front被显示器读取，无法acquire，最多两个渲染同时并行
* ![1](../assets/img/blog/vulkan/并行帧.png)
* 之前只有一个VkCommandBuffer、VkSemaphore、VkFence时：
  * 只有一个VkCommandBuffer时，为了防止数据竞争（clear/new record），我们控制只有当i-1帧的Submit渲染完成，才会让fence发出信号，Acquire请求新的图像并执行接下来的流程，这会浪费GPU性能，让它空闲等待
* 变为VkCommandBuffer、VkSemaphore、VkFence数组时：
  * 当前帧i需要等待i-2帧渲染完成，也就是不需要等待i-1帧，这样可以两帧并行渲染
* 使用时使用frame id，每帧流程后都会对++frame id % max frame，清理数组

# 重建swapchain

* 当窗口大小改变时，窗口表面会发生变化，导致交换链大小不再与之兼容，因此要捕获此事件和重建swapchain
* 流程：
  * 初始化窗口：glfwSetFramebufferSizeCallback当窗口大小改变时，就会调用它的回调函数，glfwSetWindowUserPointer将参数2任意用户数据指针与参数1GLFW 窗口关联，通过glfwGetWindowUserPointer获取用户指针，在回调函数中，让bool开关打开
  * 清理SwapChain：将清理操作抽象出来到函数中，包括VkSwapchainKHR，VkImageView，VkFramebuffer
  * 重新创建SwapChain：清理并重建（先通过glfwGetFramebufferSize获取帧缓冲大小（单位是像素，物理大小，随窗口大小按比例改变），当宽高为0时，会等待窗口事件，不会渲染）
  * 每帧：在Acquire后和Present后，如果VK_ERROR_OUT_OF_DATE_KHR交换链已变得与表面不兼容，就重建SwapChain，并退出函数，由于窗口未关闭，因此会继续下一次drawFrame流程

# 顶点数据描述

* 之前顶点数据直接放在shader中，现在我们要定义在cpp中，传入到shader中
* 流程：
  * 顶点数据：将3个顶点的位置和颜色数据存放在数组中，每个元素都是Vertex自定义类型
  * VkVertexInputBinding
  * Description顶点输入绑定，包含绑定编号，字节间隔，顶点属性寻址是依赖于逐顶点还是逐实例
  * VkVertexInputAttributeDescription顶点输入属性描述，包含数据的绑定编号，着色器输入位置编号，数据的尺寸和类型，相对于顶点输入绑定的元素起始位置的字节偏移量（通过offsetof（class 类型，类成员），获取成员的偏移量）
  * VkPipeline：在VkPipelineVertexInputStateCreateInfo中，为vertexBindingDescriptionCount,vertexAttributeDescriptionCount设置数量和数据
  * shader：把vs中定义的顶点数据删除，改为layout(location = index) in 从外部输入

# VkBuffer、VkDeviceMemory

* VkDeviceMemory物理设备内存：从GPU的memoryHeaps上分配的内存，数据（顶点，索引，uniform，纹理）的实际存储位置，抽象出来让我们自己定义分配策略
* VkBuffer缓冲：GPU上分配的内存的关联绑定（包装），以及指定此内存的相关描述（使用方式,共享模式）
* 流程：
  * 初始化：
    * 创建VkBuffer：VkBufferCreateInfo，包含缓冲区的大小（以字节为单位），指定缓冲区的允许使用方式（VK_BUFFER_USAGE_VERTEX_BUFFER_BIT缓冲区用于vkCmdBindVertexBuffers），指定当多个队列家族访问缓冲区时的共享模式（独占 / 共享），vkCreateBuffer创建缓冲区
    * VkMemoryRequirements内存需求，包含所需内存量的大小（根据VkBuffer使用vkGetBufferMemoryRequirements获取），以字节为单位，缓冲在已分配的内存区域中开始的字节偏移量，需求的内存类型
    * 分配VkDeviceMemory：
      * VkMemoryAllocateInfo内存分配，包含
        * 分配的字节数为VkMemoryRequirements的大小，
        * 从VkMemoryRequirements获取内存类型索引（vkGetPhysicalDeviceMemoryProperties获取物理设备所有内存属性（返回结果结构体包含两个数组 memoryTypes 和 memoryHeaps这个内存用来存放数据分为不同的内存类型，目前只关心memoryTypes），检查Requirements的内存类型索引，和是否有VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT主机访问标志以便CPU可以写入(比如memcpy)，如果有返回对应索引）
        * vkAllocateMemory创建内存
    * 关联：vkBindBufferMemory将VkBuffer和VkDeviceMemory绑定，关联起来
    * 填充VkDeviceMemory：vkMapMemory将GPU内存映射到CPU的地址空间，让CPU能够直接读写这块内存(下面将称为映射内存)中，vkUnmapMemory取消映射，内部通过memcpy将顶点数据填充到GPU上分配的内存中
    * 要注意：驱动程序可能不会立即将数据复制到缓冲内存中，导致内存中不可见，解决问题分为两种办法：
      * 内存类型VK_MEMORY_PROPERTY_HOST_COHERENT_BIT内存类型，这可能导致比显式刷新稍差的性能
      * 在写入映射的内存后调用 vkFlushMappedMemoryRanges，在从映射的内存读取之前调用 vkInvalidateMappedMemoryRanges
  * 每帧：
    * 绑定：在recordCommandBuffer中，vkCmdBindVertexBuffers绑定顶点缓冲
    * drawcall中，使用顶点数据的大小
  * 销毁：vkDestroyBuffer，vkFreeMemory

# 暂存缓冲区

* 此标记VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT的内存可以被CPU写入，但是GPU读取会较慢，此标记VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT的内存不可被被CPU写入，但是GPU读取会较快，因此我们首先创建HOST_VISIBLE的CommandBuffer，然后将vertex数据写入，然后将数据copy到DEVICE_LOCAL的CommandBuffer中，以便被GPU快速读取
* 缓冲区复制命令需要支持传输操作的queueFamily，任何具有 VK_QUEUE_GRAPHICS_BIT 或 VK_QUEUE_COMPUTE_BIT 功能的queueFamily,都已经隐式支持 VK_QUEUE_TRANSFER_BIT
* 流程：
  * 初始化：
    * 先创建staging暂存的VkBuffer和VkDeviceMemory，它的flag包括之前使用的VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT和VK_MEMORY_PROPERTY_HOST_COHERENT_BIT，还要新增VK_BUFFER_USAGE_TRANSFER_SRC_BIT源，最后将vertex数据存储在staging的Memory中
    * 再创建非staging的VkBuffer和VkDeviceMemory，有VK_BUFFER_USAGE_TRANSFER_DST_BIT | VK_BUFFER_USAGE_VERTEX_BUFFER_BIT, VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT标志
    * 拷贝buffer：
      * 创建新的CommandBuffer，和之前一样使用VkCommandBuffer调用vkAllocateCommandBuffers
      * vkBeginCommandBuffer，调用vkCmdCopyBuffer,大小指定为vertex数据的大小
      * 此命令需要提交到queue上执行，vkQueueSubmit，info中也要引用CommandBuffer
  * 销毁：使用完staging版本的，和CommandBuffer，就可以立即销毁了

# 索引缓冲

* 现在绘制矩形，顶点需要6个，可以用索引缓冲解决这个问题，现在需要4个顶点
* 流程：
  * 初始化:
    * 修改vertex数据，新建indices数据
    * 新建indices的VkBuffer和VkDeviceMemory，和vertex一致，不同点就是数据的改变
    * 在recordCommandBuffer中和vertex一样，也要vkCmdBindIndexBuffer绑定缓冲
  * 销毁：vkDestroyBuffer，vkFreeMemory

# VkDescriptorSetLayout

* VkDescriptorSetLayout描述符集布局：用于指定pipline将要访问的实际uniform数据的相关描述（比如shader中对应的index、类型和数量，类似于VBO的VkVertexInputBindingDescription和VkVertexInputAttributeDescription，不过它不是绑定到pipline的固定功能阶段中，而是vkCmdBindDescriptorSets以便在每帧中可以更新）
* 数量：一个VkDescriptorSetLayout可以有多个VkDescriptorSetLayoutBinding绑定点，VkDescriptorPool数量\==LayoutCount 可以有多个VkDescriptorPoolSize，VkBuffer、VkDeviceMemory、VkDescriptorSet数量\== imageCount，VkWriteDescriptorSet的数量为LayoutCount * imageCount
* 和VBO/IBO不同，uniform数据是动态数据（意味着会被CPU写入），CPU写入GPU读取（三缓冲时），多线程同时读写同一数据，造成数据竞争，访问到不正确的结果，解决办法（加锁但会浪费性能，访问不同数据）是UBO以及VkDescriptorSet需要数组形式，其元素数量和swapchain的image数量一致，这是因为由于同步原语的限制，CPU最多更新imageCount个有效数据
* 流程：
  * 初始化:
    * 定义uniform数据，MVP矩阵，并填充数据（glm库函数，以及std::chrono可以随时间更新）
    * 和VBO和IBO一样创建VkBuffer、VkDeviceMemory用于存储uniform数据，vkMapMemory启用映射，并填充数据
    * VkDescriptorSetLayoutBinding，包含在shader中对应的绑定点index，描述符数量（此绑定点有多少同类型对象，以数组为单位，即数组的元素数量为多少），描述符的类型（我们使用uniform缓冲区），采样器，指定哪个管线着色器阶段可以访问此资源（位掩码，我们在vs阶段），VkDescriptorSetLayoutCreateInfo，包含VkDescriptorSetLayoutBinding的数量和引用，vkCreateDescriptorSetLayout
    * pipline的VkPipelineLayoutCreateInfo中，DescriptorLayout的数量和引用
    * vs中：layout(binding = 0) uniform 传入数据，gl_Position应用MVP矩阵
  * 每帧：memcpy填充数据
  * 销毁：vkDestroyDescriptorSetLayout，vkDestroyBuffer，vkFreeMemory

# VkDescriptorPool、VkDescriptorSet

* VkDescriptorPool描述符池：用于分配VkDescriptorSet
* VkDescriptorSet描述符集：需要从DescriptorPool分配，会关联layout，以及绑定实际VkBuffer（包装），用于shader访问uniform全局变量（它可以被指定的pipline stag访问，在每帧drawcall前可以更改值）
* 流程：
  * 初始化:
    * 内存对齐：
      * c++自动应用默认内存对齐，可能不符合vulkan内存对齐的要求
      * vulkan内存对齐要求：标量需要按照4字节对齐，vec2需要按照8字节对齐，vec3/vec4/mat4需要按照16字节对齐
      * 解决方式
        * 在struct成员中，使用alignas(x)来手动控制成员按照x字节对齐
        * 也可以#define GLM_FORCE_DEFAULT_ALIGNED_GENTYPES，这样就不必考虑这些对齐要求
    * VkDescriptorPoolSize，包含总描述符数量（此绑定点有多少同类型对象 * VkDescriptorSet的数量），VkDescriptorPoolCreateInfo，包含VkDescriptorPoolSize数量和引用，从池中分配的最大VkDescriptorSet数量，vkCreateDescriptorPool
    * VkDescriptorSetAllocateInfo，包含VkDescriptorPool的引用，从VkDescriptorPool分配的VkDescriptorSet的数量，VkDescriptorSetLayout引用，vkAllocateDescriptorSets分配
    * VkDescriptorBufferInfo，包含VkBuffer引用（每个set关联各自对应的buffer），偏移量，数据大小，VkWriteDescriptorSet，包含要更新的VkDescriptorSet，描述符集中的描述符的index，绑定内的起始字节偏移量，描述符类型，描述符数量（此set对应的数量），VkDescriptorBufferInfo的引用，vkUpdateDescriptorSets将GPU资源更新到set中
  * 每帧：vkCmdBindDescriptorSets
  * 销毁:vkDestroyDescriptorPool
  * ![1](../assets/img/blog/vulkan/矩形.png)

# VkImage、VkImageMemoryBarrier

* VkImage图像：之前它是由swapchain自动创建的，现在我们自己创建，它和VkBuffer很相似，不同的是它用于纹理，也是需要bind关联memory
* VkImageMemoryBarrier屏障：图像布局转换最常见的方法之一是使用Barrier，并且Barrier也属于同步原语之一，具有同步对资源的访问作用（比如读写）
* 和ubo数据不同，它不是动态数据，是一张不变的纹理，因此不会写入，也就不会数据竞争，所以只用创建1个不用创建image数量个
* 流程：
  * 导入stb_image库，并包含头文件
  * 初始化:
    * 加载数据：通过stb_image库加载纹理资源，它将返回unsigned char类型数组，以及纹理宽高和通道，使用完数据后，要stbi_image_free释放数组内存
    * staging：依旧先创建staging的VkBuffer、VkDeviceMemory，把获取的数据填入
    * VkImage：VkImageCreateInfo，包含
      * 图像类型（将以哪种坐标系寻址，分为1D2D3D），
      * 尺寸（宽高的纹素数量，深度），
      * mipmap数量，
      * 图像中的层数，
      * 格式（应与VkBuffer一样的格式，否则copy失败），
      * 纹理单元块（纹素）的排列方式（VK_IMAGE_TILING_LINEAR线性贴图（数组），CPU读写方便（手动填充memory数据而非memcpy，就像操作数组一样），GPU访问效率低（shader采样，渲染目标写入，显示器读取……），VK_IMAGE_TILING_OPTIMAL最优平铺，CPU读写不方便（可能为块状排列，压缩格式，交错排列……），GPU更高效的内存访问），
      * initialLayout 指定了图像所有子资源的初始 VkImageLayout
      * 图像的预期用途（图像的布局），
      * 每个纹理单元的采样数，
      * 被多个队列家族访问时的共享模式，
      * vkCreateImage（虽然也可以让shader访问buffer中的值，但image可以使用2D坐标更快的访问）
    * Memory：vkAllocateMemory分配内存，之前VkBuffer+Memory，现在VkImage+Memory，两个缓冲之间需要copy（虽然也可以创建staging image，但从buffer->image的方式在某些硬件上更快），但是在其copy前后需要建立Barrier
    * transitionImageLayout图像布局转换：
      * VkImageMemoryBarrier，包含
        * 源布局，
        * 目标布局，
        * 如果你使用屏障来传输队列族所有权，QueueFamilyIndex应为队列族的索引，如果不想这样做，应指定默认值VK_QUEUE_FAMILY_IGNORED，
        * 受此barrier影响的VkImage句柄
        * 受此barrier影响的图像的特定部分
          * mipmap级别和数量，
          * 层级别（图像数组会使用）和数量），
          * 访问掩码（我们还要关心资源的同步问题，因此你必须指定哪些涉及资源的操作类型必须在屏障之前发生/等待屏障，在第一次transition前不需要等待任何，write需要等待第一次transition完成，第二次transition需要等待write完成，read需要等待第二次transition完成）
      * 命令：
        * vkBeginCommandBuffer，
        * vkCmdPipelineBarrier此操作会将数据从stagingMemory 拷贝到ImageMemory（需要指定哪个管线阶段必须在屏障之前发生/等待屏障），包含VkPipelineStageFlags，VkImageMemoryBarrier的引用，
        * vkEndCommandBuffer，
        * Submit，
        * 我们将应用两次转换，第一次在copy前，layout转换为TRANSFER_DST，第二次在copy后，layout转换为SHADER_READ
    * copy：VkBufferImageCopy，包含像素值开始的缓冲区中的字节偏移量,bufferRowLength 和 bufferImageHeight像素在内存中的布局方式，imageSubresource、imageOffset和imageExtent字段指示我们要将像素复制到图像的哪一部分，vkBeginCommandBuffer，vkCmdCopyBufferToImage，vkEndCommandBuffer，Submit
  * 销毁：vkDestroyImage，vkFreeMemory

# VkImageView、VkSampler

* VkImageSampler图像采样器：用于从VkImage采样颜色
* 流程：
  * 初始化:
    * PhysicalDevice：在选择合适的PhysicalDevice时，应该保证支持的Features中支持samplerAnisotropy采样
    * LogicalDevice：deviceFeatures.samplerAnisotropy = VK_TRUE;控制PhysicalDevice的采样功能启用
    * VkSamplerCreateInfo，包含放大、缩小时的过滤算法，UVW坐标在 [0,1) 范围外的寻址模式，是否启用各向异性过滤，使用的各向异性值限制，预定义边框颜色，是否使用归一化纹理坐标来寻址图像的纹理单元，是否在查找过程中与参考值的比较，指定比较运算符，指定应用于查找的mipmap滤波器，vkCreateSampler
    * 将之前创建VkImageView的部分抽象出来封装到函数中
  * 销毁：vkDestroySampler、vkDestroyImageView

# VkDescriptorSet

![1](../assets/img/blog/vulkan/组件关系.png)

* 流程：
  * 初始化:
    * 顶点数据，新增纹理坐标，VkVertexInputAttributeDescription中新增绑定location
    * VkDescriptorSetLayoutCreateInfo新增VkDescriptorSetLayoutBinding绑定（绑定点为1（之前ubo数据为0），描述符数量1，类型为图像采样，采样器为空，阶段标志为fs阶段），绑定点数量变为数组元素数2
    * VkDescriptorPool新增VkDescriptorPoolSize（描述符数量依旧==image数量，因为不是数组形式），修改PoolSize的数量和数据引用
    * 新增VkDescriptorImageInfo（之前是VkDescriptorBufferInfo），关联VkImageView（之前descriptor和buffer关联，现在和image的包装imageview关联）、VkSampler
    * 新增VkWriteDescriptorSet（绑定点改为1，描述符类型图像采样，引用VkDescriptorImageInfo）
    * vs：layout(location = 2)新增布局，并把它out输出给fs
    * fs：layout(binding = 1) uniform sampler2D新增纹理传入，和in接收vs的输出，颜色值从texture采样
    * ![1](../assets/img/blog/vulkan/纹理.png)

# 深度测试

* 流程：
  * 初始化:
    * 修改测试场景：顶点、索引数据：我们创建两个具有前后关系（z值不同）的quad作为测试场景
    * 创建附件：
      * VkImage（对于格式获取物理设备支持的格式特性，如果候选格式中支持需要的特定则选择它，纹理单元排列方式OPTIMAL因为不需要手动按纹素填充数据），Memory（CPU不需要memcpy而是由GPU深测阶段填充，因此memory类型是VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT对GPU访问进行了优化），最后将image和memory绑定
      * 为image创建ImageView，格式和image一致，指定图像的哪些方面包含在视图中（此处为深度）
      * framebuffer：需要把新的imageview作为framebuffer的attachment的一部分
    * 创建附件描述：
      * 新增VkAttachmentDescription深度附件描述，和color不同的是，深度数据不需要呈现，因此pipline使用后不需要保留数据，因此storeOp可以指定dont care，把这个附件添加到VkRenderPassCreateInfo中
      * 为subpass新增VkAttachmentReference
      * 修改VkSubpassDependency，这里我们只创建了一个image，因此在dependency中应该等待之前的所有subpass深度写入完成
    * 设置深度测试的状态：
      * Pipeline中VkPipelineDepthStencilStateCreateInfo，设置为启用和测试方式
    * vs：把顶点属性的ve2变为ve3
  * 每帧：新增深度的VkClearValue
  * 销毁：vkDestroyImageView、vkDestroyImage、vkFreeMemory
  * ![1](../assets/img/blog/vulkan/深度测试.png)

# 加载模型

* 流程：
  * 初始化:
    * 我们将使用 tinyobjloader 库，加载obj文件，LoadObj获取数据，通过遍历范围值，将获得Vertex数据（pos，纹理坐标）和indices数据，把之前场景使用的顶点数据删除就好
    * 渲染模型和渲染自定义的网格体，没什么差异，其实就是改一下使用的顶点数据
    * 注意我们使用glm是，S\*R\*T\*V的顺序
    * ![1](../assets/img/blog/vulkan/模型导入.png)

# mipmap

* 流程：
  * 初始化:
    * 为纹理生成mipmap：
      * mipLevels级别取决于原分辨率的大小,新生成的个数为log2 ^max(width, height),再加上原图像即+1
      * 依旧把纹理数据存储在staging memory中，创建image时，应指定mipLevel数量，usage需要新增TRANSFER_SRC
      * 第一次transitionImageLayout图像布局转换时（转换为TRANSFER_DST），也应指定mipLevel数量，然后正常执行copy操作（VkBuffer+Memory -> VkImage+Memory），不需要第二次图像布局转换（转换为SHADER_READ）
      * 生成mipmap：