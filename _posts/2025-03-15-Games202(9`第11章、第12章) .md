---
title: Games202(9`第11章、第12章)
date: 2025-03-15 12:00:00 +0800
categories: [Games202]
tags: [实时渲染]     # TAG names should always be lowercase
math: true
---
# 第11章

## Linearly Transformed Cosines（LTC->线性变换的余弦）

为了解决microfacet models的shading问题，就是在 多边形光源的照射下 快速求出在ggx模型上 不考虑shadow的 任意一点的Shading.

**整体steps：**

* 波瓣旋转：固定入射方向，经过线性变换，将出射波瓣朝向转为向上（将任意方向lobe转换为固定cos函数）
  * 入射光旋转：wi变为新的ωi'
* 光源旋转：将p点分别和光源4个顶点相连，获得4个方向同样线性变换

**具体steps：**

* 从rendering equation开始，由于认为wi都是uinform，因此可以拆出积分

![1742022634554](/assets/img/blog/Games202/线性变换.png)

* 需要把F(ωi)通过线性变换M^-1把所有的ωi变为新的方向ωi',从而使F(ωi)变为cos. 其中分母是归一化的操作
* rendering equation的F部分，转换为cos(wi`)，即对于固定cos函数的新入射光方向，对于dwi部分，用wi的等式进行换元
* 换元后的部分是纯微积分,我们需要引入一个雅克布项-J.去求解它

## Disney's principle BRDF迪士尼原则

**microfacet models有一些问题**

* 无法解释多层材质
* 让artist艺术家使用繁琐

**设计原则**

Disney's principle BRDF诞生的首要目的就是为了让artist使用方便,因此它遵守这些设计原则

* 使用更直观的名词（次表面反射，金属度，镜面反射程度, 镜面反射+颜色,粗糙度,各向异性程度，光晕，光晕+颜色，透明层的明显程度，透明层的光泽层），所有的属性可以混合在一起使用
* 让brdf参数数量少一点
* 有左右边界值
* 允许小于0或大于1，以便做特殊效果

**优缺点：**

* 优点：显示出很多不同的材质，更容易理解的参数
* 缺点：并不是完全基于物理的，参数冗余

## Non-Photorealistic Rendering(NPR)非照片真实感的渲染

风格化渲染：NPR偏向于这种卡通的风格，它通常基于真实渲染的结果，保留很多photorealistic的东西

#### outline rendering 描边

* 基于法线着色:当v和n点乘结果小于某个阈值（vn接近垂直），则着色区域是contour edges
* 基于几何:渲染一个更大的模型，整体颜色为描边色，不允许看见正面
* 基于图像的后期处理:先渲染一个正常的图像，利用filter kernel(卷积核)对每个像素重新计算，得到描边

#### color blocks.色块

想要亮灰暗部分界限分明，进行取整操作，以高光为例,如果一些值值超过了1.5,则认为全是1.5，没超过但大于0的,我们认为全都是0.8,而那些本来就是0的依旧是0.

#### Stroke surface stylization素描风格

* 首先关于不同明暗设计不同的纹理
* 对于不同明暗的纹理设计mipmap，这样可以保证物体距离远近时，整体亮度不变

# 第12章 Real - Time Ray Tracing

_先简单说一下Geometric - Buffers几何缓冲区：G-Buffer用来分别存储屏幕空间的信息（位置，法线，基础颜色，镜面颜色……）_

**正文：**

RTRT与path tracing相比,只是进行了算法上的简化,算法的核心思路不变，都需要ray tracing和降噪的（由于蒙特卡洛采样形成的噪声）

如何对于即使1spp(Samples Per Pixel像素采样数)得到的大量噪声的结果，通过降噪仍可以快速得到高质量的效果，那就要用到Industrial工业界的解决实时渲染降噪的方法

## Temporal Denoising Solution时间降噪方法

#### temporal accumulation 时间累计

在每一个新的帧i渲染时，渲染器会根据之前帧 < i 的信息，并将当前帧的渲染数据与这些历史信息进行加权平均（衰减式的加权），会随着时间增加使画面越来越清晰

**找到上一帧信息**

想要获取上一帧i的信息，就需要知道上一帧i-1对应在哪个像素上，也就是uv(i)->world(i)->world(i-1)->uv(i-1)，

![1742030852103](/assets/img/blog/Games202/世界坐标.png)

要获得世界坐标s，需要当前uv坐标x与MVP和E视口矩阵的逆矩阵相乘

![1742030991222](/assets/img/blog/Games202/上一帧位置.png)

要获得上一帧的世界坐标s·，就需要让当前世界坐标s 乘以T变换（Model部分 / motion vector）的逆矩阵

找到当前像素在上一帧对应物体，在当前画面中对应的像素位置，motion vector和相机运动方向是相反的

![1742031205373](/assets/img/blog/Games202/uv坐标.png)

要获得上一帧的uv坐标x·，需要s·乘以EPVM

**混合**

![1742035664903](/assets/img/blog/Games202/混合.png)

在找到上一帧的信息后就可以加权混合，第一个公式按空间混合，第二个按时间线性混合，其中~ : unfiltered 表示没有filter的内容，- : filtered 表示已经filter的内容，a 表示平衡系数，即当前帧的贡献

**一些问题**

* 突然切换了场景 / 缩放相机（场景变多）/ 相机位移，没有上一帧信息，
* 切换了光源颜色，就不能再用上一帧的信息了，否则颜色不正确，

![1742038651359](/assets/img/blog/Games202/拖尾.png)

* 上一帧权重超过0.8时 / 光源移动场景不移动 会造成拖尾，
  * 比如2这里，很大部分保留了上一帧柜子的颜色和自身墙面颜色混合，所以呈现绿色（camera向左移动，物体相对相机右移，因此查询方向是向右的），
  * 对于1这里，保留了之前所有帧不同权重的混合，因此接近于白色，
  * 对于绿条中间夹杂的白色是柜子两侧的边框，因为和墙面差不多颜色，没有明显拖尾现象

对于拖尾情况，有两种解决方法：

* clamping限制：把上一帧结果限制到当前结果的近似，再混合
* detection检测：当在世界找到i-1的位置时，判断它们是否是同一个物体id，如果id不同，a就不再用0.8而是其他百分比混合
